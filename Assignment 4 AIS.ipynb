{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments #\n",
    "\n",
    "This notebook imports data from one of three publicly available sources (ETCCDI, HADEX_ref1961-1990, and HADEX_ref1981-2010) for weather observations, and **is designed \n",
    "to show trends**. \n",
    "For that purpose weather data are grouped into logical categories ('Warm', 'Cold', 'Wet', 'Dry', and 'Extremes')\n",
    "\n",
    "The user is then able to zoom into individual states, as well as select one of the categories via radio buttons.\n",
    "\n",
    "**I have deliberately not displayed any y-values**, because the main purpose is to display trends, not specific values.\n",
    "Because the different datasets within each category all represent different measurements (i.e. mm of rain, number of days, temperature) they naturally occupy significantly differnt ranges of y-values.\n",
    "\n",
    "Therefore **I have chosen to normalise each dataset** so it's values range from 0 to 1, and then plot them stacked (non-additive), so they don't overlap. When possible I have plotted a faint 3rd-degree polynomal regression curve to emphasise clear trends if they exist.\n",
    "\n",
    "The original data contain obviously significant noise, which made it also harder to discern trends. I therefore am plotting a 10 year rolling average, which smoothes out the lines a fair bit. If the purpose of these graphs where to detect outlier and extremes, this would of course not be an acceptable technique.\n",
    "\n",
    "The original data are provided as directories with thousands of individual csv files, one for each weather-observation category and each weather station.\n",
    "To import these files takes a significant amount of time. I have therefore provided a csv file which contains my finished DataFrame which is much, much faster to import.\n",
    "To demonstrate however that I constructed that dataframe from the original data by combining many different datafiles I have also provided a method `importAllAndStore()` to import from the original data (and then save the final DataFrame into a csv file).\n",
    "\n",
    "This code could be fairly easily adapated to display climate trends from other countries, since the data-format seems to be identical internationally (as far as I checked). Apart from various constants, the main method that would need to be adapted is loadWeatherStations(), which is necessary to group the weatherstations into states.\n",
    "\n",
    "**To test simply run all cells top to bottom.**\n",
    "\n",
    "The code as it is imports and uses data from the HADEX_ref1981-2010 dataset, but that can easily be changed as this is fully parameterised.\n",
    "\n",
    "To do a **quick test** with the prepared and exported dataframe, place the file `Climate-Trends-Australia-HADEX_1961.csv` into the working directory, and run the code as is.\n",
    "\n",
    "**To test the original import**, expand and create a `Data` folder in the working directory, and place the expanded data into it. Because the datafiles are large, I compressed them separately for each data source - you only need to download the one you chose to use. Execute `importAllAndStore()` once, then run the notebook again top to bottom (exept for `importAllAndStore()` ).\n",
    "\n",
    "Folder structure for import from original data:\n",
    "\n",
    "`Data\n",
    "   ETCCDI Climate Change indices\n",
    "       Australia\n",
    "           CDD\n",
    "           CSDI\n",
    "           ...\n",
    "           WSDI\n",
    "   HADEX_ref1961-1990\n",
    "       stn-indices\n",
    "           CDD_6190\n",
    "           CSDI_6190\n",
    "           ...\n",
    "           WSDI_6190\n",
    "   HADEX_ref1981-2010\n",
    "       stn-indices\n",
    "           CSDI_8110\n",
    "           R95p_8110\n",
    "           ...\n",
    "           WSDI_8110\n",
    "   Stations.csv`\n",
    "\n",
    "If using this code, please acknowledge original author, **Angelika Sajani**\n",
    "\n",
    "\n",
    "# URLS #\n",
    "\n",
    "Explanation of observed indices:  https://www.climdex.org/learn/indices/#index-FD \n",
    "\n",
    "Hadex Datasets: https://www.climdex.org/access/   (I found the 1961-1990 dataset to be the most comprehensive) \n",
    "\n",
    "ETCCDI Datasets: http://etccdi.pacificclimate.org/data.shtml   \n",
    "\n",
    "Australian Weather Stations (as part of downloading other data): http://www.bom.gov.au/metadata/catalogue/19115/ANZCW0503900447#dataset-constraints\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import pandas as pd\n",
    "import pandas.io.excel as excl\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button, CheckButtons, RadioButtons, AxesWidget\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "### Constants to select the data source #############################\n",
    "HADEX_1961 = 'HADEX_1961'\n",
    "HADEX_1981 = 'HADEX_1981'\n",
    "ETCCDI = 'ETCCDI'\n",
    "\n",
    "HADEX_COUNTRY_CODE = 'AS' # all files from Australia in the HADEX_~ data sources start with this letter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Weather Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a dataframe containing information about weather stations, with a six-digit string index 'SiteID'\n",
    "# SiteIDs are prefixed with zeroes if (as a number) they contain less than 6 digits\n",
    "# Extracted columns: 'Site Name', 'Longitude', and 'State'\n",
    "\n",
    "def loadWeatherStations():\n",
    "    \n",
    "    rowsToSkip = [0, 1, 3] + list(range(19399, 19406))\n",
    "    useCols = [0, 2, 6, 8]\n",
    "    df = pd.read_csv('./Data/stations.csv', skiprows=rowsToSkip, usecols=useCols)\n",
    "\n",
    "    # remove sites from islands and Antartica, as their climate would be very different from the mainland\n",
    "    df = df[(df['STA'] != 'ISL') & (df['STA'] != 'ANT')]\n",
    "\n",
    "    # index by weather station ID\n",
    "    df.set_index('Site', inplace=True)\n",
    "        \n",
    "    df.columns = ['Site Name', 'Longitude', 'State']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Tester #######\n",
    "# _ws = loadWeatherStations()\n",
    "# print(_ws.head())\n",
    "# print(_ws.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Source Specific Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selectors:             required key parameters       result        comments\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "#  'isValidDataFileName' fileName and eventCode        boolean       True if fileName is a valid weather data file\n",
    "#  'dataFolderPath'      eventCode                     boolean       Relative  (to pwd) folder path for data files\n",
    "#  'annualColumnWidths'  none                          [int]         list of two column widths to import data files\n",
    "#                                                                       which contain one annual value per row\n",
    "#  'monthlyColumnWidths' none                          [int]         list of 14 column widths to import data files\n",
    "#                                                                       which contain one annual value per row\n",
    "#  'siteIdFromFileName'  fileName                      str           six-character weather station ID (all digits)\n",
    "#  'eventDictionary'     none                          dictionary    A dictionary describing available weather events \n",
    "\n",
    "\n",
    "def getForSource(selector, source, fileName=None, eventCode=None, basePath=None):\n",
    "    \n",
    "    # -------------------------------------------------------------------------------------------------------------    \n",
    "    # values that are at the moment independent of the datasource but may not always be\n",
    "    \n",
    "    if (selector == 'annualColumnWidths'):\n",
    "        return  [4, 7] # the column widths in each file, 4 characters for the year, the rest is the value\n",
    " \n",
    "    elif (selector == 'monthlyColumnWidths'):\n",
    "        return  [4] + [8] * 13 # the column widths in each file, 4 characters for the year, the rest is the value\n",
    "\n",
    "    elif (selector == 'eventDictionary'):\n",
    "        return  defineEvents(source)  # in its own function for readability\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------    \n",
    "    if source == HADEX_1961:\n",
    "        if selector == 'isValidDataFileName':\n",
    "            if (fileName is None) or (eventCode is None):\n",
    "                raise ValueError('You must pass values for key-parameters fileName and eventCode')    \n",
    "            return fileName.startswith(HADEX_COUNTRY_CODE) and fileName.endswith('_6190_' + eventCode + '.txt')\n",
    "  \n",
    "        elif selector == 'dataFolderPath':\n",
    "            return './Data/HADEX_ref1961-1990/stn-indices/' + eventCode + '_6190/'\n",
    "        \n",
    "        elif selector == 'siteIdFromFileName':\n",
    "            if (fileName is None):\n",
    "                raise ValueError('You must pass a value for key-parameter fileName')    \n",
    "            return fileName[5:11] \n",
    "   \n",
    "    # -------------------------------------------------------------------------------------------------------------    \n",
    "    elif source == HADEX_1981:\n",
    "        if selector == 'isValidDataFileName':\n",
    "            if (fileName is None) or (eventCode is None):\n",
    "                raise ValueError('You must pass values for fileName, eventCode, and basePath');   \n",
    "            return fileName.startswith(HADEX_COUNTRY_CODE) and fileName.endswith('_8110_' + eventCode + '.txt')\n",
    "\n",
    "        elif selector == 'dataFolderPath':\n",
    "            return './Data/HADEX_ref1981-2010/stn-indices/' + eventCode + '_8110/'\n",
    "        \n",
    "        elif selector == 'siteIdFromFileName':\n",
    "            if (fileName is None):\n",
    "                raise ValueError('You must pass a value for key-parameter fileName')    \n",
    "            return fileName[5:11]   \n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------    \n",
    "    elif source == ETCCDI:\n",
    "        if selector == 'isValidDataFileName':\n",
    "            if (fileName is None) or (eventCode is None):\n",
    "                raise ValueError('You must pass values for fileName, eventCode, and basePath')    \n",
    "            return fileName.endswith('.' + eventCode)\n",
    " \n",
    "        elif selector == 'dataFolderPath':\n",
    "            return './Data/ETCCDI Climate Change indices/Australia/' + eventCode + '/'\n",
    "        \n",
    "        elif selector == 'siteIdFromFileName':\n",
    "            if (fileName is None):\n",
    "                raise ValueError('You must pass a value for key-parameter fileName')    \n",
    "            return fileName[0:6]\n",
    "\n",
    "    # -------------------------------------------------------------------------------------------------------------    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid value for parameter 'source' ({source}).\")    \n",
    "    \n",
    " \n",
    "    # if we get here, we didn't have a valid selector, as for every valid selector there is a return statement\n",
    "    raise ValueError(f\"Invalid value for parameter 'selector' ({selector}).\");    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Tester #######\n",
    "# source = 'ETCCDI'\n",
    "# print(getForSource('isValidDataFileName', source, fileName='ASH30018044_8110_R95pTOT.txt', eventCode='R95pTOT'))\n",
    "# print(getForSource('dataFolderPath', source, eventCode='CDD'))\n",
    "# print(getForSource('annualColumnWidths',  source))\n",
    "# print(getForSource('monthlyColumnWidths', source))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate Events to Examine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defineEvents(source):\n",
    " \n",
    "    eventCodes = None\n",
    "    \n",
    "    allEvents = {\n",
    "            'CDD': {\n",
    "                'Label': 'Consecutive Dry Days',\n",
    "                'colour': 'sienna',\n",
    "                'monthly': False,\n",
    "                'category': 'Dry'\n",
    "            },  \n",
    "            'CSDI': {\n",
    "                'Label': 'Cold Spell Duration', \n",
    "                'colour': 'blue',\n",
    "                'monthly': False,\n",
    "                'category': 'Cold'\n",
    "            },  \n",
    "            'CWD': {\n",
    "                'Label': 'Consecutive Wet Days',\n",
    "                'colour': 'darkgreen',\n",
    "                'monthly': False,\n",
    "                'category': 'Wet'\n",
    "            },  \n",
    "            'DTR': {\n",
    "                'Label': 'Daily Temp. Range',\n",
    "                'LongLabel': 'Daily Temperature Range',\n",
    "                'colour': 'magenta',\n",
    "                'monthly': True,\n",
    "                'category': 'Extremes'\n",
    "            },  \n",
    "            'ETR': {\n",
    "                'Label': 'Extreme Temp. Range',\n",
    "                'LongLabel': 'Extreme Temperature Range',\n",
    "                'colour': 'darkviolet',\n",
    "                'monthly': True,\n",
    "                'category': 'Extremes'\n",
    "            },  \n",
    "            'FD': {\n",
    "                'Label': 'Frost Days',\n",
    "                'colour': 'deepskyblue',\n",
    "                'monthly': False,\n",
    "                'category': 'Cold'\n",
    "            },   \n",
    "            'GSL': {\n",
    "                'Label': 'Growing Season Dur.',\n",
    "                'LongLabel': 'Growing Season Duration',\n",
    "                'colour': 'tomato',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            },  \n",
    "            'PRCPTOT': {\n",
    "                'Label': 'Annual Total Rain',\n",
    "                'LongLabel': 'Annual Total Precipitation',\n",
    "                'colour': 'green',\n",
    "                'monthly': False,\n",
    "                'category': 'Wet'\n",
    "            }, \n",
    "            'R95p': {\n",
    "                'Label': 'Wet Days',\n",
    "                'colour': 'lime',\n",
    "                'monthly': False,\n",
    "                'category': 'Wet'\n",
    "            },\n",
    "            'R95pTOT': {\n",
    "                'Label': 'Rain from Wet Days',\n",
    "                'colour': 'mediumseagreen',\n",
    "                'monthly': False,\n",
    "                'category': 'Wet'\n",
    "            },\n",
    "            'R99p': {\n",
    "                'Label': 'Very Wet Days',\n",
    "                'colour': 'green',\n",
    "                'monthly': False,\n",
    "                'category': 'Extremes'\n",
    "            }, \n",
    "            'R99pTOT': {\n",
    "                'Label': 'Rain Very Wet Days', \n",
    "                'LongLabel': 'Rain from Very Wet Days', \n",
    "                'colour': 'seagreen',\n",
    "                'monthly': False,\n",
    "                'category': 'Extremes'\n",
    "            },\n",
    "            'SDII': {\n",
    "                'Label': 'Rain Intensity',\n",
    "                'LongLabel': 'Precipitation Intensity Index',\n",
    "                'colour': 'teal',\n",
    "                'monthly': False,\n",
    "                'category': 'Extremes'\n",
    "            }, \n",
    "            'SU': {\n",
    "                'Label': 'Summer Days',\n",
    "                'colour': 'red',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            },  \n",
    "            'TN10p': {\n",
    "                'Label': 'Cold Nights',\n",
    "                'colour': 'cyan',\n",
    "                'monthly': False,\n",
    "                'category': 'Cold'\n",
    "            }, \n",
    "            'TN90p': {\n",
    "                'Label': 'Warm Nights', \n",
    "                'colour': 'indianred',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            }, \n",
    "            'TR': {\n",
    "                'Label': 'Tropical Nights',\n",
    "                'colour': 'crimson',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            }, \n",
    "            'TX10p': {\n",
    "                'Label': 'Cold Days',\n",
    "                'colour': 'mediumturquoise',\n",
    "                'monthly': False,\n",
    "                'category': 'Cold'\n",
    "            },\n",
    "            'TX90p': {\n",
    "                'Label': 'Hot Days',\n",
    "                'colour': 'darkred',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            },\n",
    "            'WSDI': {\n",
    "                'Label': 'Warm Spell Dur.',\n",
    "                'LongLabel': 'Warm Spell Duration',\n",
    "                'colour': 'orangered',\n",
    "                'monthly': False,\n",
    "                'category': 'Warm'\n",
    "            } \n",
    "        }\n",
    "        \n",
    "    if source == HADEX_1961:\n",
    "        return allEvents\n",
    "    \n",
    "    elif source == HADEX_1981:\n",
    "        eventCodes = ['CSDI', 'R95p', 'R95pTOT', 'R99p', 'R99pTOT', 'TN10p', 'TN90p', 'TX10p', 'TX90p', 'WSDI']\n",
    "        eventCodes = ['CSDI', 'R95pTOT', 'R99pTOT', 'TN10p', 'TN90p', 'TX10p', 'TX90p', 'WSDI']\n",
    "\n",
    "    elif source == ETCCDI: \n",
    "        result = allEvents\n",
    "        result.pop('ETR', None)\n",
    "        result.pop('R95pTOT', None)\n",
    "        result.pop('R99pTOT', None)\n",
    "        return result \n",
    "\n",
    "\n",
    "    \n",
    "    # If we get here, and don't have an eventCodes list,\n",
    "    #   we didn't have a valid source\n",
    "    if eventCodes is None:\n",
    "        raise ValueError(f\"Invalid value for parameter 'source' ({source}).\");    \n",
    "\n",
    "    # all good, create a dictionary with all the keys in eventCodes from dictionary allEvents\n",
    "    result = dict()\n",
    "    for eventCode in eventCodes:\n",
    "        result[eventCode] = allEvents[eventCode]\n",
    "        \n",
    "    return result \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Tester #######\n",
    "# x = defineEvents(HADEX_1961)\n",
    "# e = x['CDD']\n",
    "# e.get('LongLabel', e['Label'])\n",
    "# print()\n",
    "# print(defineEvents(HADEX_1961))\n",
    "# print()\n",
    "# print(defineEvents(HADEX_1981))\n",
    "# print()\n",
    "# print(defineEvents(ETCCDI))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilteredEvents(dataSource, categoryFlags):\n",
    "\n",
    "    # allEvents is a dictionary, key is eventCode, 'category' contains 'Warm', 'Cold', 'Wet', 'Dry', or 'Extremes'\n",
    "    allEvents = defineEvents(dataSource)\n",
    "  \n",
    "    # categoryFlags is a simple dictionary, key is a category, value is a boolean\n",
    "    selectedCategories = []\n",
    "    for category, flag in categoryFlags.items():\n",
    "        if flag:\n",
    "            selectedCategories += [category]\n",
    "    \n",
    "    result = dict()\n",
    "    if not allEvents is None:\n",
    "        for eventCode, eventData in allEvents.items():\n",
    "            if eventData['category'] in selectedCategories:\n",
    "                result[eventCode] = eventData # add this event to the result\n",
    "    return result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Tester #######\n",
    "# categoryFlags = {'Warm': True, 'Cold': False, 'Wet': False, 'Dry': False}\n",
    "# getFilteredEvents(HADEX_1961, categoryFlags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Returns a dataframe which contains two columns: 'year', value, and index 'SiteID'\n",
    "# # - the value column is float, it's column name is the same as the event code, i.e. 'CDD' for 'consecutive dry days'\n",
    "# # - the SiteID is a six-digit string (prefixed with zeroes if necessary) identifying the source weather station\n",
    "\n",
    "# eventData is the entry for eventCode from the eventDictionary\n",
    "\n",
    "def importOneEvent(eventCode, eventData, source):\n",
    "\n",
    "    result = None\n",
    "    folderPath = getForSource('dataFolderPath', source, eventCode=eventCode)\n",
    "    monthlyData = eventData['monthly']\n",
    "    columnWidths = getForSource('monthlyColumnWidths', source) if monthlyData else getForSource('annualColumnWidths', source)\n",
    "\n",
    "    # Data for each weather station are stored in separate fixed width files\n",
    "    # convention for file name:\n",
    "    #   siteID with 6 digits (prefixed with zeroes if possible)\n",
    "    #   extension is the same as the event code, i.e. '.CDD' for 'consecutive dry days'\n",
    "    rowsToSkip = list(range(0, 10)) # skip rows 0 to 9\n",
    "   \n",
    "    fileNames = None\n",
    "    try:\n",
    "        fileNames = os.listdir(folderPath)\n",
    "    except:\n",
    "        print(f\"ERROR: Could not find the directory for event code '{eventCode}' and data source '{source}'.\")\n",
    "        print(f\"PATH:  {folderPath}\")\n",
    " \n",
    "    if fileNames is not None:\n",
    "\n",
    "        # first pass: count valid files so we can show import-percentage\n",
    "        n = 0\n",
    "        for fileName in fileNames:\n",
    "            if getForSource('isValidDataFileName', source, fileName=fileName, eventCode=eventCode):\n",
    "                n += 1\n",
    "\n",
    "        # second pass, do the actual import\n",
    "        counter = 0\n",
    "        for fileName in fileNames:\n",
    "            if getForSource('isValidDataFileName', source, fileName=fileName, eventCode=eventCode):\n",
    "                counter += 1\n",
    "                print(f'\\r   {counter / n:>3.0%}  {fileName:30}', end='')\n",
    "                # determine site ID from file name\n",
    "                siteID = getForSource('siteIdFromFileName', source, fileName=fileName)\n",
    "                # read the file (fixed width)\n",
    "                filePath = os.path.join(folderPath, fileName)\n",
    "                df = pd.read_fwf(filePath, widths=columnWidths, skiprows=rowsToSkip)\n",
    "                \n",
    "                if monthlyData: # we only need the first and last column\n",
    "                    df = df.iloc[:, [0, 13]]\n",
    "\n",
    "                # standardise the name of the column containing the event-code, and capitalise the 'year' column\n",
    "                df.columns = ['Year', eventCode] # the column is already the code but not capitalised -> ensure 100% standardisation\n",
    "                # filter out rows that don't contain a value\n",
    "                df = df[df[eventCode] >= 0]  # empty row are marked with -99.0 or -99.9\n",
    "                # filter out years before the period we are interested in\n",
    "                # df = df[df['Year'] >= FIRST_YEAR]\n",
    "\n",
    "                # add a column to store the site ID and create a Site:Year combined index\n",
    "                df['Site'] = int(siteID)\n",
    "                df.set_index(['Site', 'Year'], inplace=True)\n",
    "                \n",
    "                # normalise so that all curves roughly have the same scale\n",
    "                mx = df[eventCode].max()\n",
    "                if mx != 0.0:\n",
    "                    df[eventCode] /= mx\n",
    "\n",
    "                # if this is the first iteration, the result is the new data frame\n",
    "                # subsequently, append the new data frame to the existing result\n",
    "                if result is None:\n",
    "                    result = df\n",
    "                else:\n",
    "                    result = pd.concat([result, df])\n",
    "    print('')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Tester #######\n",
    "# _eventCode = 'SDII'\n",
    "# _evdict = getFilteredEvents(ETCCDI, extreme=1)\n",
    "# # print(_evdict)\n",
    "# x = importOneEvent(_eventCode, _evdict[_eventCode], ETCCDI)\n",
    "# if x is None:\n",
    "#     print('No data')\n",
    "# else:\n",
    "#     print(x.shape)\n",
    "#     print(x.head())\n",
    "#     print(x.tail())\n",
    "#     print(x.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importEvents(eventDictionary, df_stations, source):\n",
    "\n",
    "    result = None\n",
    "    \n",
    "    # counters are just for progress feedback\n",
    "    n = len(eventDictionary)\n",
    "    i = 0\n",
    "    for eventCode, eventData in eventDictionary.items():\n",
    "        i += 1\n",
    "        print(f\"{i}/{n} -- Importing '{eventData['Label']}' data\")\n",
    " \n",
    "       \n",
    "        df = importOneEvent(eventCode, eventDictionary[eventCode], source)\n",
    "        if df is None:\n",
    "            pass\n",
    "        elif result is None:\n",
    "            result = df\n",
    "        else:\n",
    "            # index in both dfs is Site and Year\n",
    "            result = pd.merge(result, df, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    # reset the index to 'Site' alone, so we can easily join it with the weather station data\n",
    "    if result is None:\n",
    "        print('Could not find any data for any of the events.')\n",
    "    else:\n",
    "        result = result.reset_index().set_index('Site')\n",
    "        result = pd.merge(result, df_stations, how='inner', left_index=True, right_index=True)\n",
    "\n",
    "        return result   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAveragesByState(fig, df, whichWeatherEvents, thisStateOnly=None):\n",
    "\n",
    "    N = 10 # days over which the running average is calculated\n",
    "    DKG = '#303030'\n",
    "    \n",
    "    if thisStateOnly is None:\n",
    "        COLS = 3\n",
    "        DELTA = 0.6 # offset per curve when plotting them on top of each other\n",
    "        zoomed = False\n",
    "        statesToPlot = ['Australia'] + sorted(df.State.unique())\n",
    "        superTitle = 'Australia - Climate Trends'\n",
    "    else:\n",
    "        DELTA = 1 # offset per curve when plotting them on top of each other\n",
    "        COLS = 1\n",
    "        zoomed = True\n",
    "        statesToPlot = [thisStateOnly]\n",
    "        superTitle = thisStateOnly + ' - Climate Trends'\n",
    "\n",
    "    nStates = len(statesToPlot)\n",
    "    ROWS = math.ceil(nStates / COLS)\n",
    "       \n",
    "    fig.suptitle(superTitle, x=0.05, ha='left', fontsize=11, fontweight='demibold', c=DKG)\n",
    "    \n",
    "    plotIndex = 1    # 1 .. ROWS*COLS\n",
    "    stateIndex = 0   # 0 .. nStates\n",
    "    axesToPlaceLegend = None\n",
    "    axesToGetLegend = None\n",
    "    axes = None\n",
    "    for row in range(0, ROWS):\n",
    "        for col in range(0, COLS):\n",
    "                      \n",
    "            # if plotting all states, jump over the top-right quandrant to draw the legend\n",
    "            if (zoomed): \n",
    "                doPlot = True\n",
    "            elif stateIndex >= nStates: # index runs from 0..nStates-1\n",
    "                doPlot = False\n",
    "            elif (row == 0) and (col == COLS-1):  # this is whre we place the legend\n",
    "                doPlot = False\n",
    "            else:\n",
    "                doPlot = True\n",
    "\n",
    "            if doPlot:\n",
    "                axes = plt.subplot(ROWS, COLS, plotIndex, sharex=axes, sharey=axes)\n",
    "                axes.yaxis.set_ticks_position('none')\n",
    "                axes.yaxis.set_ticks_position('none')\n",
    "\n",
    "                if not zoomed: \n",
    "                    if (stateIndex == 0):   # if not zoomed, first one is always Australia\n",
    "                        axesToGetLegend = axes\n",
    "                    if (row == 0) and (col == COLS-2):\n",
    "                        axesToPlaceLegend = axes\n",
    "                \n",
    "                state = statesToPlot[stateIndex]\n",
    "                if (state == 'Australia'):\n",
    "                    df_toPlot = df\n",
    "                else:\n",
    "                    df_toPlot = df[df['State'] == state]\n",
    "                if not zoomed:\n",
    "                    axes.set_title(state, y=0.98, x=0.5, ha='center', fontsize=9, c=DKG)\n",
    "                    \n",
    "                # group by year, calculating mean\n",
    "                df_toPlot = df_toPlot.groupby('Year').mean()\n",
    "\n",
    "                nCurves = len(whichWeatherEvents)\n",
    "                curveIndex = 0\n",
    "                offset = DELTA * nCurves\n",
    "                \n",
    "                # We will plot one curve for each weather event\n",
    "                for eventCode, eventData in whichWeatherEvents.items():\n",
    "                    x = df_toPlot.index  # x-data\n",
    "                    y = df_toPlot[eventCode] # y-data\n",
    "                    curveIndex += 1\n",
    "                    offset -= DELTA  # this corresponds to the value 0 in the current curve\n",
    "                    \n",
    "                    # ------------------------------------------------------------------------------------------------\n",
    "                    # Because they may have very different scales, we normalise each curve to values between 0 and 1.\n",
    "                    # Then, to avoid them overlapping in the graph, we offset them each by a given y-constant DELTA\n",
    "                    # Make offset decrease down to zero, so curve order corresponds with legend order\n",
    "                    # ------------------------------------------------------------------------------------------------\n",
    "                    \n",
    "                    # Plot a faint, thin, grey line between each curve, so that any up- or down-trend is better visible\n",
    "                    if zoomed and offset > 0:\n",
    "                        axes.axhline(y=offset, xmin=0, xmax=1, lw=0.5, alpha=0.3, c='grey')\n",
    "\n",
    "                    # minimum and maximum required for normalisation\n",
    "                    mn = y.min()\n",
    "                    mx = y.max()\n",
    "                    \n",
    "                    # for a few events, i.e. frost days, all values are zero for most states\n",
    "                    # rather than plot a weird looking straight line, don't plot anything\n",
    "                    if mn == mx: \n",
    "                        if zoomed:\n",
    "                            plt.text(1920, offset + DELTA * 0.45, 'No ' + eventData['Label'], ha='left', fontsize=20, c='grey')\n",
    " \n",
    "                    # normal case\n",
    "                    else: \n",
    "                        y = (y - mn) / (mx - mn) + offset  # normalisation\n",
    "\n",
    "                        # Try and plot a regression curve (third degree polynomal).\n",
    "                        # Plot faint but double thick line to make it better visible\n",
    "                        #  without detracting from the actual curve\n",
    "                        try: \n",
    "                            a, b, c, d = np.polyfit(x, y, 3)\n",
    "                            axes.plot(x, a*x**3 + b*x*x + c*x + d, \\\n",
    "                                      c=eventData['colour'], alpha=0.3, linestyle='--', lw=2.0, \\\n",
    "                                      zorder=curveIndex * 100)\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        # Do a line plot\n",
    "                        # use an N-day average to minimise noise and make trends easier to see\n",
    "                        yRoll = y.rolling(N, win_type='triang').mean()\n",
    "                        axes.plot(x, yRoll, label=eventData['Label'], \\\n",
    "                                  color = eventData['colour'], zorder=curveIndex)\n",
    "                        \n",
    "                    \n",
    "                # ------------------------------------------------------------------------------------------------\n",
    "                # Back to iterating over plots (states)  -- beautify\n",
    "                # ------------------------------------------------------------------------------------------------\n",
    "\n",
    "                # instead of a legend which would waste a lot of space, directly plot labels \n",
    "                if zoomed:\n",
    "                    _, xMax = axes.get_xlim()\n",
    "                    _, yMax = axes.get_ylim()\n",
    "                    yPos = DELTA * nCurves\n",
    "                    i = 0\n",
    "                    for _, eventData in whichWeatherEvents.items():\n",
    "                        if i == 0 and len(whichWeatherEvents) == 1:\n",
    "                            yForText = yMax\n",
    "                        elif i == 0:\n",
    "                            yForText = yMax\n",
    "                        else:\n",
    "                            yForText = yPos\n",
    "                        plt.text(xMax * 0.999, yForText - 0.05, \\\n",
    "                                 eventData.get('LongLabel', eventData['Label']), \\\n",
    "                                 ha='right', va='top', fontsize=9, c=DKG)\n",
    "                        yPos -= DELTA\n",
    "                        i += 1\n",
    "\n",
    "                # Hide y ticklabels as they are meaningless\n",
    "                for label in axes.get_yticklabels():\n",
    "                    label.set_visible(False)\n",
    "\n",
    "                # Since x-axis is shared, hide x-ticklabels for all but the bottom row\n",
    "                #  but leave the ticklines\n",
    "                if row < ROWS - 1:\n",
    "                    for label in axes.get_xticklabels():\n",
    "                        label.set_visible(False)   \n",
    "\n",
    "                # Make frame, ticks and tick labels dark grey\n",
    "                # some curves refer to degress, others to mm, others to counts\n",
    "                for label in axes.get_xticklabels():\n",
    "                    label.set_color(DKG)\n",
    "                for line in axes.get_xticklines():\n",
    "                    line.set_color(DKG)\n",
    "                for pos in ['bottom', 'top', 'right', 'left']:\n",
    "                    axes.spines[pos].set_color(DKG)\n",
    "    \n",
    "                # important: must be inside of    if doPlot:\n",
    "                stateIndex += 1\n",
    "\n",
    "            # important: must be outside of    if doPlot:\n",
    "            plotIndex += 1\n",
    " \n",
    "    if zoomed:\n",
    "        plt.subplots_adjust(left = 0.05, bottom=0.05, right=0.8, top=0.89) \n",
    "    else:\n",
    "        # we need room for state labels above, and legend to the right\n",
    "        plt.subplots_adjust(left = 0.05, bottom=0.05, right=0.79, top=0.90)    \n",
    " \n",
    "    # When showing all states show a shared legend\n",
    "    # If zoomed plot labels for each state\n",
    "    if not zoomed and axesToPlaceLegend is not None:\n",
    "        handles, labels = axesToGetLegend.get_legend_handles_labels()\n",
    "        axesToPlaceLegend.legend(handles, labels, \\\n",
    "                             bbox_to_anchor=(1.7, 1.0), loc='upper center', borderaxespad=0., \\\n",
    "                             fontsize=9, labelcolor=DKG)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFigure():\n",
    "    fig = plt.figure(num=42, clear=True)\n",
    "    fig.tight_layout()\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation and selection of which events to show #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Controller:\n",
    "\n",
    "    def __init__(self, figure, df, dataSource, initialFlags, \\\n",
    "                 buttonDimensions=[0.05, 0.9, 0.1, 0.05], \\\n",
    "                 checkboxDimensions=[0.6, 0.5, 0.3, 0.2]):\n",
    "\n",
    "        # everyting we need to plot\n",
    "        self.figure = figure\n",
    "        self.df = df\n",
    "        self.currentState = None\n",
    "        self.dataSource = dataSource\n",
    "        # for backbutton\n",
    "        self.buttonDimensions = buttonDimensions  # set of four floats, xpos, ypos, width, height\n",
    "        # for checkboxex\n",
    "        self.categoryFlags = initialFlags\n",
    "        self.checkboxDimensions = checkboxDimensions  # set of four floats, xpos, ypos, width, height\n",
    "        \n",
    "        # references to object we have to prevent from being garbage collected\n",
    "        self.cid = None\n",
    "        self.backButton = None\n",
    "        self.checkBoxes = None\n",
    "        self.radioButtons = None\n",
    " \n",
    "        self.connectZoom() \n",
    "        self.connectSelectButtons()\n",
    "\n",
    "       \n",
    "    def connectZoom(self):\n",
    "        self.cid = self.figure.canvas.mpl_connect('button_press_event', self.zoom)\n",
    "\n",
    "        \n",
    "    def disconnectZoom(self):\n",
    "        if self.cid is not None:\n",
    "            plt.disconnect(self.cid)\n",
    "        self.cid = None\n",
    "\n",
    "        \n",
    "    def connectBackButton(self):\n",
    "        # for a button to remain responsive, we need to keep a reference to it\n",
    "        # therefore it is easier to create it here rather than inside plotAveragesByState\n",
    "        self.backButton = Button(plt.axes(self.buttonDimensions), 'Back')\n",
    "        self.backButton.on_clicked(self.back)\n",
    " \n",
    "\n",
    "    def disconnectBackButton(self):\n",
    "        self.backButton = None # allow this button to be garbage collected\n",
    "\n",
    "\n",
    "    def connectSelectButtons(self):\n",
    "        labels = list(self.categoryFlags.keys())\n",
    "        flags = list(self.categoryFlags.values())\n",
    "#         self.checkBoxes = CheckButtons(plt.axes(self.checkboxDimensions), labels, flags)\n",
    "#         self.checkBoxes.on_clicked(self.clickedCB)\n",
    "                                 \n",
    "        i = 0\n",
    "        for category, flag in self.categoryFlags.items():\n",
    "            if flag:\n",
    "                break\n",
    "            i += 1\n",
    "        self.radioButtons = RadioButtons(plt.axes(self.checkboxDimensions), labels, active=i, activecolor='#505050')\n",
    "        self.radioButtons.on_clicked(self.clickedRB)\n",
    "    \n",
    "    \n",
    "    def disconnectSelectButtons(self):\n",
    "        self.checkBoxes = None # allow these to be garbage collected\n",
    "\n",
    "        \n",
    "    def zoom(self, event):\n",
    "        axes = event.inaxes;\n",
    "        if axes is not None:\n",
    "            state = axes.get_title() # we must do this before we clear the figure\n",
    "            if state is not None and state != '': \n",
    "                self.disconnectZoom()\n",
    "                self.currentState = state\n",
    "                self.plotState()\n",
    "  \n",
    "\n",
    "    def back(self, event):\n",
    "        self.disconnectBackButton()\n",
    "        self.currentState = None\n",
    "        self.plotAll()\n",
    "        \n",
    "                    \n",
    "    def plotState(self):\n",
    "        self.figure.clear()\n",
    "        \n",
    "        plotAveragesByState(self.figure, self.df, self.get_selectedEvents(), thisStateOnly=self.currentState)\n",
    "        self.connectBackButton()\n",
    "        self.connectSelectButtons()\n",
    "        self.figure.canvas.draw()\n",
    "              \n",
    "                \n",
    "    def plotAll(self):\n",
    "        self.figure.clear()\n",
    "        \n",
    "        plotAveragesByState(self.figure, self.df, self.get_selectedEvents())\n",
    "        self.connectZoom()\n",
    "        self.connectSelectButtons()\n",
    "        self.figure.canvas.draw()\n",
    "       \n",
    "    \n",
    "    def clickedCB(self, label):\n",
    "        self.categoryFlags[label] = not self.categoryFlags[label]\n",
    "        \n",
    "        if self.currentState is None:\n",
    "            self.plotAll()\n",
    "        else:\n",
    "            self.plotState()\n",
    "\n",
    "    def clickedRB(self, label):\n",
    "        for category in self.categoryFlags.keys():\n",
    "            self.categoryFlags[category] = (category == label)\n",
    "        \n",
    "        if self.currentState is None:\n",
    "            self.plotAll()\n",
    "        else:\n",
    "            self.plotState()\n",
    "\n",
    "\n",
    "    def get_selectedEvents(self):\n",
    "        return getFilteredEvents(self.dataSource, self.categoryFlags)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Convenience - import the original data once and store in one .csv file ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the original data are stored in thousands of separate files\n",
    "# import is greatly sped up if we import them once and then store the entire df in a csv file\n",
    "\n",
    "def makeFullFileName(dataSource, partFileName):\n",
    "    return partFileName + '-' + dataSource + '.csv'\n",
    "    \n",
    "\n",
    "def importAllAndStore(dataSource, fileName='Climate-Trends-Australia'):\n",
    "\n",
    "    # load the weather stations\n",
    "    df_stations = loadWeatherStations()\n",
    "    \n",
    "    # Load the data for all weather events, station and year, as available\n",
    "    # Index will be indexed by SiteID\n",
    "    allEvents = defineEvents(dataSource)\n",
    "    df = importEvents(allEvents, df_stations, dataSource)\n",
    "\n",
    "    if df is None:\n",
    "        print('We could not find any data for this combination of weather events.')\n",
    "    else:\n",
    "        try:\n",
    "            df.to_csv(makeFullFileName(dataSource, fileName))\n",
    "            print('Done')\n",
    "        except:\n",
    "            print('An error occurred writing that file.')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tester ###\n",
    "\n",
    "# importAllAndStore(HADEX_1961)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Method # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If passing a non-empty partialFileName, \n",
    "# this will import the main datafram from the csv file rather than from the original data\n",
    "# Full filename will be <partialFileName>-<dataSource>.csv\n",
    "\n",
    "def loadAndPlotClimateTrends(dataSource=ETCCDI, partialFileName=''):\n",
    "\n",
    "    # load the weather stations\n",
    "    df_stations = loadWeatherStations()\n",
    "\n",
    "    # define which weather events we investigate, this will subsequently be controlled by checkboxes\n",
    "    categoryFlags = {'Warm': True, 'Cold': False, 'Wet': False, 'Dry': False, 'Extremes': False}\n",
    "    selectedEvents = getFilteredEvents(dataSource, categoryFlags)\n",
    "\n",
    "    # Load the data for all weather events, station and year, as available\n",
    "    # Index will be indexed by SiteID\n",
    "    df = None\n",
    "    if partialFileName == '':\n",
    "        allEvents = defineEvents(dataSource)\n",
    "        df = importEvents(allEvents, df_stations, dataSource)\n",
    "        if df is None:\n",
    "            print('We could not find any data for this combination of weather events.')\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_csv(makeFullFileName(dataSource, partialFileName))\n",
    "        except:\n",
    "            print('Could not import csv file.')\n",
    "\n",
    "    # create a figure, and draw the inial plot\n",
    "    fig = createFigure()\n",
    "    plotAveragesByState(fig, df, selectedEvents)\n",
    "\n",
    "    # create interactive controllers\n",
    "    controller = Controller(fig, df, dataSource, \\\n",
    "                          initialFlags=categoryFlags,\\\n",
    "                          buttonDimensions=[0.05, 0.905, 0.1, 0.04], \\\n",
    "                          checkboxDimensions=[0.835, 0.698, 0.15, 0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entry Point #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HADEX_1961 = 'HADEX_1961' ### best of the three data sources\n",
    "# HADEX_1981 = 'HADEX_1981'\n",
    "# ETCCDI = 'ETCCDI'  \n",
    "\n",
    "loadAndPlotClimateTrends(dataSource=HADEX_1961, partialFileName='Climate-Trends-Australia')\n",
    "# loadAndPlotClimateTrends(dataSource=HADEX_1961, partialFileName='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
